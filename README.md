# ğŸ¬ TrendScope-AI

**Real-Time Big Data & MLOps Platform for Movie Trend Analysis**

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![Kafka](https://img.shields.io/badge/Kafka-7.5.0-black.svg)](https://kafka.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5.0-orange.svg)](https://spark.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.9.2-0194E2.svg)](https://mlflow.org/)

---
![Platform UI Screenshot](./ReadME_images/ui1.png)






![Platform UI Screenshot](./ReadME_images/ui2.png)
## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Configuration](#configuration)
- [Project Structure](#project-structure)
- [Components](#components)
- [Monitoring](#monitoring)
- [Development](#development)
- [Troubleshooting](#troubleshooting)
- [License](#license)

---

## ğŸ¯ Overview

TrendScope-AI is an end-to-end real-time data streaming and analytics platform that monitors and predicts **movie trends** by combining:

- **Structured data** from The Movie Database (TMDB) API
- **Unstructured discussions** from Reddit (r/movies)

The platform demonstrates modern Big Data, MLOps, and real-time analytics capabilities:

âœ… Real-time data ingestion with **Apache Kafka**  
âœ… Stream processing with **Apache Spark Structured Streaming**  
âœ… Adaptive predictions using **Online Machine Learning (River)**  
âœ… MLOps pipeline with **MLflow**, **Evidently**, **Prometheus**, and **Grafana**  
âœ… Fully containerized with **Docker Compose**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  TMDB API    â”‚              â”‚  Reddit API   â”‚                â”‚
â”‚  â”‚ (Structured) â”‚              â”‚ (Unstructured)â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INGESTION LAYER (Kafka)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚TMDB Producer â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ tmdb_stream   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚Reddit Producerâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ reddit_stream â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROCESSING LAYER (Spark Streaming)                  â”‚
â”‚  â€¢ Parse & Clean JSON                                            â”‚
â”‚  â€¢ Sentiment Analysis (VADER)                                    â”‚
â”‚  â€¢ Windowed Aggregations                                         â”‚
â”‚  â€¢ Join TMDB + Reddit streams                                    â”‚
â”‚  â€¢ Compute TrendScore                                            â”‚
â”‚                                                                   â”‚
â”‚  TrendScore = wâ‚Ã—Popularity + wâ‚‚Ã—Mentions + wâ‚ƒÃ—Sentiment         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cassandra DB   â”‚         â”‚   trend_stream        â”‚
â”‚  (Trend Data)    â”‚         â”‚   (Kafka Topic)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ONLINE ML LAYER (River)                             â”‚
â”‚  â€¢ Consume trend_stream                                          â”‚
â”‚  â€¢ Extract features (popularity, sentiment, mentions)            â”‚
â”‚  â€¢ Predict TrendScore(t+Î”)                                       â”‚
â”‚  â€¢ Update model incrementally                                    â”‚
â”‚  â€¢ Track metrics (MAE, RMSE, RÂ²)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cassandra DB   â”‚         â”‚ predictions_stream    â”‚
â”‚  (Predictions)   â”‚         â”‚   (Kafka Topic)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 MONITORING & MLOPS LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ MLflow  â”‚  â”‚Evidently â”‚  â”‚Prometheusâ”‚  â”‚ Grafana â”‚          â”‚
â”‚  â”‚(Tracking)â”‚  â”‚ (Drift)  â”‚  â”‚(Metrics) â”‚  â”‚ (Viz)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### ğŸ”„ Real-Time Data Pipeline
- Continuous ingestion from TMDB and Reddit APIs
- Fault-tolerant message delivery with Kafka
- Stream processing with Spark Structured Streaming

### ğŸ§  Online Machine Learning
- Adaptive trend prediction using River
- Incremental model updates with each observation
- Feature engineering (temporal, delta, moving averages)

### ğŸ“Š Hybrid Data Integration
- Structured movie metadata (TMDB)
- Unstructured sentiment from Reddit discussions
- Real-time sentiment analysis with VADER

### ğŸ¯ TrendScore Computation
Combines multiple signals:
- **Popularity** (TMDB metrics)
- **Mentions Rate** (Reddit activity)
- **Sentiment** (Audience reactions)

### ğŸ“ˆ Complete MLOps Pipeline
- Experiment tracking (MLflow)
- Data drift detection (Evidently)
- System monitoring (Prometheus)
- Real-time dashboards (Grafana)

### ğŸ³ Production-Ready Deployment
- Fully containerized with Docker Compose
- One-command deployment
- Scalable microservices architecture

---

## ğŸ”§ Prerequisites

- **Docker** (version 20.10+)
- **Docker Compose** (version 2.0+)
- **TMDB API Key** ([Get it here](https://www.themoviedb.org/settings/api))
- **Reddit API Credentials** ([Create app here](https://www.reddit.com/prefs/apps))

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/Aziz-Benamira/TrendScope-AI.git
cd TrendScope-AI
```

### 2. Configure Environment Variables

```bash
cp .env.example .env
```

Edit `.env` and add your API credentials:

```env
TMDB_API_KEY=your_tmdb_api_key_here
REDDIT_CLIENT_ID=your_reddit_client_id_here
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here
REDDIT_USER_AGENT=TrendScope-AI/1.0
```

### 3. Run Setup Script

**On Linux/macOS:**
```bash
chmod +x setup.sh
./setup.sh
```

**On Windows (PowerShell):**
```powershell
.\setup.ps1
```

### 4. Access Dashboards

- **Grafana**: http://localhost:3000 (admin/admin)
- **MLflow**: http://localhost:5000
- **Prometheus**: http://localhost:9090
- **Spark UI**: http://localhost:8080

---

## âš™ï¸ Configuration

### TrendScore Weights

Adjust in `.env`:

```env
W1_POPULARITY=0.4   # Weight for TMDB popularity
W2_MENTIONS=0.3     # Weight for Reddit mentions
W3_SENTIMENT=0.3    # Weight for sentiment score
```

### Window Parameters

```env
TREND_WINDOW_DURATION=5 minutes
TREND_SLIDE_DURATION=1 minute
```

### Fetch Intervals

```env
TMDB_FETCH_INTERVAL=300    # 5 minutes
REDDIT_FETCH_INTERVAL=60   # 1 minute
```

---

## ğŸ“ Project Structure

```
TrendScope-AI/
â”‚
â”œâ”€â”€ producers/              # Data ingestion services
â”‚   â”œâ”€â”€ tmdb/              # TMDB API producer
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ tmdb_producer.py
â”‚   â””â”€â”€ reddit/            # Reddit API producer
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ reddit_producer.py
â”‚
â”œâ”€â”€ processors/            # Spark streaming jobs
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ spark_streaming_processor.py
â”‚
â”œâ”€â”€ ml_service/           # Online ML service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ online_ml_service.py
â”‚
â”œâ”€â”€ storage/              # Database initialization
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ init_cassandra.py
â”‚
â”œâ”€â”€ monitoring/           # Monitoring & MLOps
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â””â”€â”€ drift_detection.py
â”‚
â”œâ”€â”€ configs/              # Configuration files
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ tests/                # Unit tests
â”‚
â”œâ”€â”€ docker-compose.yml    # Orchestration
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env.example         # Environment template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ”© Components

### 1ï¸âƒ£ Data Ingestion Layer

**TMDB Producer**
- Fetches trending movies every 5 minutes
- Publishes to `tmdb_stream` Kafka topic
- Includes: popularity, votes, metadata

**Reddit Producer**
- Streams r/movies comments in real-time
- Extracts movie mentions
- Publishes to `reddit_stream` Kafka topic

### 2ï¸âƒ£ Processing Layer

**Spark Structured Streaming**
- Consumes both Kafka streams
- Applies VADER sentiment analysis
- Performs windowed aggregations (5-minute windows)
- Joins TMDB + Reddit data by movie title
- Computes TrendScore
- Writes to Cassandra and `trend_stream`

### 3ï¸âƒ£ Online ML Layer

**River ML Service**
- Consumes `trend_stream`
- Extracts features (popularity, mentions, sentiment, temporal)
- Predicts next TrendScore using online regression
- Updates model incrementally
- Tracks MAE, RMSE, RÂ² metrics
- Publishes predictions to `predictions_stream`

### 4ï¸âƒ£ Storage Layer

**Cassandra**
- `movie_trends`: Processed trend data
- `predictions`: ML predictions and actuals
- `model_metrics`: Performance metrics

### 5ï¸âƒ£ Monitoring Layer

**MLflow**: Experiment tracking, model versioning  
**Evidently**: Data drift detection  
**Prometheus**: Metrics collection  
**Grafana**: Real-time dashboards

---

## ğŸ“Š Monitoring

### Grafana Dashboard

Access at http://localhost:3000 (default: admin/admin)

**Panels:**
- ML Model MAE/RMSE trends
- Total predictions counter
- Prediction latency (p95)
- Predictions per minute

### MLflow Tracking

Access at http://localhost:5000

- View experiment runs
- Compare model performance
- Track parameters and metrics

### Prometheus Metrics

Access at http://localhost:9090

Key metrics:
- `ml_predictions_total`: Total predictions
- `ml_mae`: Mean Absolute Error
- `ml_rmse`: Root Mean Square Error
- `ml_prediction_seconds`: Prediction latency

---

## ğŸ› ï¸ Development

### Running Individual Components

```bash
# Start only Kafka ecosystem
docker-compose up -d zookeeper kafka

# Start only producers
docker-compose up -d tmdb-producer reddit-producer

# View specific service logs
docker-compose logs -f ml-service
```

### Running Tests

```bash
# Install dev dependencies
pip install -r requirements.txt pytest pytest-mock

# Run tests
pytest tests/
```

### Rebuilding Services

```bash
# Rebuild specific service
docker-compose build tmdb-producer

# Rebuild and restart
docker-compose up -d --build tmdb-producer
```

---

## ğŸ› Troubleshooting

### Kafka Connection Issues

```bash
# Check Kafka is running
docker-compose ps kafka

# View Kafka logs
docker-compose logs kafka

# Restart Kafka
docker-compose restart kafka
```

### Cassandra Not Ready

```bash
# Wait for Cassandra initialization
docker-compose logs -f cassandra

# Check Cassandra status
docker-compose exec cassandra nodetool status
```

### Reset Everything

```bash
# Stop and remove all containers
docker-compose down -v

# Start fresh
docker-compose up -d
```

---

## ğŸ“š Additional Resources

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [River Online ML](https://riverml.xyz/)
- [TMDB API Documentation](https://developers.themoviedb.org/3)
- [Reddit API Documentation](https://www.reddit.com/dev/api)

---

## ğŸ“ Academic Context

This project demonstrates:

âœ… **Big Data Engineering**: Kafka, Spark, Cassandra  
âœ… **Streaming Analytics**: Real-time data processing  
âœ… **Machine Learning**: Online adaptive learning  
âœ… **MLOps**: Monitoring, tracking, drift detection  
âœ… **DevOps**: Containerization, orchestration

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¥ Contributors

- **Aziz Benamira** - [GitHub](https://github.com/Aziz-Benamira)

---

**Built with â¤ï¸ for real-time analytics and adaptive machine learning**
