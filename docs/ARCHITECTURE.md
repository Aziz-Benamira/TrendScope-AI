# ğŸ“Š TrendScope-AI - Architecture Deep Dive

## System Overview

TrendScope-AI implements a **Lambda Architecture** variant optimized for real-time streaming:

- **Speed Layer**: Real-time stream processing (Kafka + Spark Streaming)
- **Serving Layer**: Query interface (Cassandra)
- **ML Layer**: Online learning and prediction (River)
- **Monitoring Layer**: Observability and MLOps (Prometheus, Grafana, MLflow, Evidently)

---

## Data Flow

### 1. Ingestion Phase

```
TMDB API â†’ TMDB Producer â†’ Kafka (tmdb_stream)
                              â†“
                         Spark Consumer

Reddit API â†’ Reddit Producer â†’ Kafka (reddit_stream)
                                  â†“
                             Spark Consumer
```

**Key Design Decisions:**

- **Kafka as Message Bus**: Decouples producers from consumers, enables replay
- **Separate Topics**: Allows independent scaling and processing
- **JSON Serialization**: Human-readable, schema flexibility

### 2. Processing Phase

```
Spark Structured Streaming:
â”œâ”€â”€ Parse JSON from Kafka
â”œâ”€â”€ Apply transformations
â”‚   â”œâ”€â”€ Sentiment Analysis (VADER)
â”‚   â”œâ”€â”€ Movie mention extraction
â”‚   â””â”€â”€ Data cleaning
â”œâ”€â”€ Windowed Aggregations
â”‚   â”œâ”€â”€ Window: 5 minutes
â”‚   â”œâ”€â”€ Slide: 1 minute
â”‚   â””â”€â”€ Watermark: 10 minutes (handle late data)
â”œâ”€â”€ Stream Join
â”‚   â”œâ”€â”€ Join key: movie_title + window
â”‚   â”œâ”€â”€ Type: Full outer join
â”‚   â””â”€â”€ Handle missing data with coalesce
â””â”€â”€ Compute TrendScore
    â””â”€â”€ Formula: w1Ã—Pop + w2Ã—Mentions + w3Ã—Sentiment
```

**Key Design Decisions:**

- **Structured Streaming**: Exactly-once semantics, fault tolerance
- **Windowed Joins**: Handle temporal alignment of data streams
- **Watermarking**: Balance latency vs completeness for late arrivals

### 3. TrendScore Formula

```
TrendScore(t) = wâ‚ Ã— Popularity(t) 
              + wâ‚‚ Ã— MentionsRate(t) Ã— 10
              + wâ‚ƒ Ã— (Sentiment(t) + 1) Ã— 50

Where:
- wâ‚ = 0.4 (TMDB popularity weight)
- wâ‚‚ = 0.3 (Reddit mentions weight)
- wâ‚ƒ = 0.3 (Sentiment weight)
- Popularity: TMDB metric [0, âˆ)
- MentionsRate: Count per window [0, âˆ)
- Sentiment: VADER compound score [-1, 1]
```

**Normalization Strategy:**

- Mentions scaled by 10x to match popularity magnitude
- Sentiment shifted from [-1,1] to [0,100] range
- Final TrendScore typically ranges [0, 200]

### 4. ML Prediction Phase

```
River Online Learning Pipeline:
â”œâ”€â”€ Feature Engineering
â”‚   â”œâ”€â”€ Current metrics (popularity, sentiment, mentions)
â”‚   â”œâ”€â”€ Temporal features (hour, day_of_week)
â”‚   â”œâ”€â”€ Delta features (Î”mentions, Î”sentiment)
â”‚   â””â”€â”€ Moving averages (MA5)
â”œâ”€â”€ Scaling
â”‚   â””â”€â”€ StandardScaler (online mean/variance estimation)
â”œâ”€â”€ Model
â”‚   â””â”€â”€ Linear Regression (SGD optimizer, L2 regularization)
â””â”€â”€ Metrics Tracking
    â”œâ”€â”€ MAE (Mean Absolute Error)
    â”œâ”€â”€ RMSE (Root Mean Square Error)
    â””â”€â”€ RÂ² (Coefficient of Determination)
```

**Key Design Decisions:**

- **Online Learning**: Model updates with every observation
- **Feature History**: Maintains per-movie circular buffer (size: 100)
- **Incremental Scaling**: No batch retraining required
- **L2 Regularization**: Prevents overfitting with coefficient penalty

---

## Storage Architecture

### Cassandra Schema Design

**movie_trends table:**
```cql
PRIMARY KEY ((movie_title), window_start)
CLUSTERING ORDER BY (window_start DESC)
```

- **Partition key**: movie_title (distributes data across nodes)
- **Clustering key**: window_start (orders data within partition)
- **Query pattern**: "Get recent trends for movie X"

**predictions table:**
```cql
PRIMARY KEY ((movie_title), timestamp)
CLUSTERING ORDER BY (timestamp DESC)
```

- **Partition key**: movie_title
- **Clustering key**: timestamp
- **Query pattern**: "Get prediction history for movie X"

**Design Rationale:**

- Wide partition strategy (movie as partition key)
- Time-series optimized (descending timestamp order)
- Efficient range queries on recent data
- No joins required (denormalized)

---

## Monitoring Architecture

### Metrics Collection

```
ML Service â†’ Prometheus Client (Port 8000)
                â†“
            Prometheus Scraper (15s interval)
                â†“
            Prometheus TSDB
                â†“
            Grafana Queries
```

**Collected Metrics:**

- **Counters**: `ml_predictions_total`
- **Gauges**: `ml_mae`, `ml_rmse`
- **Histograms**: `ml_prediction_seconds`, `ml_update_seconds`

### MLflow Tracking

```
ML Service â†’ MLflow Tracking Server (Port 5000)
                â†“
            SQLite Backend Store
                â†“
            MLflow UI
```

**Tracked Artifacts:**

- Parameters: learning_rate, model_version
- Metrics: MAE, RMSE, RÂ² (logged every 100 predictions)
- Tags: model_type, experiment_name

### Drift Detection

```
Cassandra â†’ Drift Detection Service
    â†“
Evidently Reports (HTML)
    â†“
Reference Window (24h ago) vs Current Window (1h)
```

**Detected Drifts:**

- Feature drift (popularity, sentiment, mentions distribution)
- Prediction drift (error distribution changes)
- Data quality issues (missing values, outliers)

---

## Scalability Considerations

### Horizontal Scaling

**Kafka:**
- Partition topics (e.g., 3 partitions per topic)
- Add more brokers for increased throughput

**Spark:**
- Add worker nodes
- Increase executor memory/cores
- Tune `spark.streaming.kafka.maxRatePerPartition`

**Cassandra:**
- Add nodes to cluster
- Replication factor = 3 for production
- Partition by high-cardinality keys

**ML Service:**
- Deploy multiple instances with consumer groups
- Each instance processes different partitions

### Vertical Scaling

**Memory:**
- Spark: Increase executor/driver memory
- Kafka: Increase heap size for broker
- Cassandra: Increase heap for JVM

**CPU:**
- More cores â†’ more parallelism
- Tune Spark executor cores
- Increase Kafka threads

---

## Fault Tolerance

### Data Layer

- **Kafka**: Replication factor, ISR (In-Sync Replicas)
- **Cassandra**: Distributed, no SPOF
- **Spark**: Checkpointing for stateful operations

### Processing Layer

- **Exactly-once semantics**: Kafka + Spark idempotent writes
- **Watermarking**: Handle late data gracefully
- **Checkpoints**: Resume from last processed offset

### ML Layer

- **Model persistence**: MLflow artifacts
- **Metric recovery**: Prometheus retention
- **Consumer groups**: Automatic partition reassignment

---

## Performance Tuning

### Kafka

```env
KAFKA_NUM_PARTITIONS=3
KAFKA_REPLICATION_FACTOR=1
KAFKA_LOG_RETENTION_HOURS=24
```

### Spark

```python
spark.conf.set("spark.sql.shuffle.partitions", "10")
spark.conf.set("spark.streaming.kafka.maxRatePerPartition", "100")
spark.conf.set("spark.sql.streaming.stateStore.maintenanceInterval", "60s")
```

### Cassandra

```cql
ALTER TABLE movie_trends WITH compaction = {
    'class': 'TimeWindowCompactionStrategy',
    'compaction_window_size': '1',
    'compaction_window_unit': 'DAYS'
};
```

---

## Security Considerations

### API Security

- Store credentials in environment variables
- Use OAuth2 for Reddit (more secure than password auth)
- Rotate API keys periodically

### Network Security

- Docker network isolation
- Expose only necessary ports
- Use TLS for production (not in dev setup)

### Data Security

- No PII collection from Reddit (usernames anonymizable)
- Cassandra authentication (disabled in dev)
- Grafana admin password change required

---

## Future Enhancements

1. **HDFS Integration**: Long-term storage for raw data
2. **Kubernetes Deployment**: Replace Docker Compose for production
3. **Advanced Features**: Movie embeddings, graph analysis
4. **Real-time Alerting**: Webhook notifications for trending spikes
5. **A/B Testing**: Model version comparison
6. **AutoML**: Hyperparameter tuning with Optuna

---

**For implementation details, see the source code and inline documentation.**
